- name: Create python-ml {{ item.version_number }} container
  vars:
    - base_container_image: "{{ common_container_dir }}/python-ml-base-{{ item.base_version }}.sif"
    - container_name: "python-ml-{{ item.version_number }}"
    - container_recipe: "{{ common_container_recipe_dir }}/{{ container_name }}.def"
    - container_image: "{{ common_container_dir }}/{{ container_name }}.sif"
    - python_ml_module_dir: "{{ common_modules }}/python-ml"
    - python_ml_binary_dir: "{{ common_container_dir }}/python-ml/{{ item.version_number }}"
    - python_ml_kernel_dir: "{{ common_container_dir }}/python-ml/{{ item.version_number }}/kernels"
  tags:
    - "python-ml{{ item.version_number }}"
    - never
  block:
    - name: "Check for existence of {{ base_container_image }} container"
      stat:
        path: "{{ base_container_image }}"
      register: base_container_exists
    - name: "Missing {{ base_container_image }}"
      fail:
        msg: "The container {{ base_container_image }} is missing. Please build python-ml-base first."
      when: not base_container_exists.stat.exists
    - name: Create Python ML {{ item.version_number }} container
      when: base_container_exists.stat.exists
      block:
        - name: Copy recipe {{ container_recipe }}
          template:
            src: "common/python-ml.def"
            dest: "{{ container_recipe }}"
        - name: Build container {{ container_image }}
          command: "{{ singularity }} build {{ container_image }} {{ container_recipe }}"
          args:
            creates: "{{ container_image }}"
          become: true
    - name: Ensure python-ml binary directory exists
      file:
        path: "{{ python_ml_binary_dir }}"
        state: directory
        mode: u=rwx,g=rwx,o=rx
    - name: Ensure python-ml kernel directory exists
      file:
        path: "{{ python_ml_kernel_dir }}"
        state: directory
        mode: u=rwx,g=rwx,o=rx
    - name: Create python-ml binaries
      template:
        src: "common/{{ binary.template }}"
        dest: "{{ python_ml_binary_dir }}/{{ binary.name }}"
        mode: 0755
      with_items:
        - { name: "python", template: "python-ml.sh" }
        - { name: "python3", template: "python-ml.sh" }
        - { name: "pip", template: "python-ml.sh" }
        - { name: "pip3", template: "python-ml.sh" }
      loop_control:
        loop_var: binary

    - name: Create Jupyter kernel file
      template:
        src: "common/python-ml-kernel.json"
        dest: "{{ python_ml_kernel_dir }}/kernel.json"
        mode: 0644

    - name: Install Python ML {{ container_name }} module
      block:
        - name: Check module dir
          file:
            path: "{{ python_ml_module_dir }}"
            state: directory
            mode: u=rwx,g=rwx,o=rx
        - name: Install Python ML module file
          template:
            src: common/python-ml.lua
            dest: "{{ python_ml_module_dir }}/{{ item.version_number }}.lua"

# Shared Model Download Tasks
- name: Create Models Directory
  file:
    path: /software/common/models
    state: directory
    owner: root
    group: "{{ admin_group }}"
    mode: '0755'
  tags:
    - never
    - models

- name: Download Essential LLM Models
  vars:
    essential_models:
      - bert-base-uncased
      - sentence-transformers/all-MiniLM-L6-v2
      - sentence-transformers/all-mpnet-base-v2
      - microsoft/DialoGPT-medium
      - distilbert-base-uncased
  shell: |
    export HF_HOME=/software/common/models
    export TRANSFORMERS_CACHE=/software/common/models
    {{ singularity }} exec {{ common_container_dir }}/python-ml-0.0.2.sif python3 -c "
    from transformers import AutoTokenizer, AutoModel
    from sentence_transformers import SentenceTransformer
    model_name = '{{ item }}'
    print(f'Downloading {model_name}...')
    if 'sentence-transformers' in model_name:
        model = SentenceTransformer(model_name, cache_folder='/software/common/models')
    else:
        tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir='/software/common/models')
        model = AutoModel.from_pretrained(model_name, cache_dir='/software/common/models')
    print(f'✓ Downloaded {model_name}')
    "
  loop: "{{ essential_models }}"
  tags:
    - never
    - models
    - essential-models

- name: Download Popular Vision Models
  vars:
    vision_models:
      - microsoft/resnet-50
      - google/vit-base-patch16-224
      - facebook/deit-base-distilled-patch16-224
  shell: |
    export HF_HOME=/software/common/models
    export TRANSFORMERS_CACHE=/software/common/models
    {{ singularity }} exec {{ common_container_dir }}/python-ml-0.0.2.sif python3 -c "
    from transformers import AutoImageProcessor, AutoModel
    model_name = '{{ item }}'
    print(f'Downloading {model_name}...')
    try:
        processor = AutoImageProcessor.from_pretrained(model_name, cache_dir='/software/common/models')
        model = AutoModel.from_pretrained(model_name, cache_dir='/software/common/models')
        print(f'✓ Downloaded {model_name}')
    except Exception as e:
        print(f'⚠ Warning: Could not download {model_name}: {e}')
    "
  loop: "{{ vision_models }}"
  tags:
    - never
    - models
    - vision-models

- name: Download Large Language Models
  vars:
    large_models:
      - microsoft/DialoGPT-large
      - facebook/blenderbot-400M-distill
  shell: |
    export HF_HOME=/software/common/models
    export TRANSFORMERS_CACHE=/software/common/models
    {{ singularity }} exec {{ common_container_dir }}/python-ml-0.0.2.sif python3 -c "
    from transformers import AutoTokenizer, AutoModelForCausalLM
    model_name = '{{ item }}'
    print(f'Downloading {model_name}...')
    try:
        tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir='/software/common/models')
        model = AutoModelForCausalLM.from_pretrained(model_name, cache_dir='/software/common/models')
        print(f'✓ Downloaded {model_name}')
    except Exception as e:
        print(f'⚠ Warning: Could not download {model_name}: {e}')
        print('Note: Some models may require authentication or special access.')
    "
  loop: "{{ large_models }}"
  tags:
    - never
    - models
    - large-models